{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team 6\n",
    "* > Stadnik Oleksandr\n",
    "* > Yagoda Mykyta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx\n",
    "# !pip install matplotlib\n",
    "# !pip install tqdm\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install graphviz\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations, groupby\n",
    "\n",
    "from networkx.algorithms import tree\n",
    "from networkx.algorithms import bellman_ford_predecessor_and_distance\n",
    "from networkx.algorithms import floyd_warshall_predecessor_and_distance\n",
    "\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Algorithm's analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You can use this function to generate a random graph with 'num_of_nodes' nodes\n",
    "# and 'completeness' probability of an edge between any two nodes\n",
    "# If 'directed' is True, the graph will be directed\n",
    "# If 'draw' is True, the graph will be drawn\n",
    "def gnp_random_connected_graph(num_of_nodes: int,\n",
    "                               completeness: int,\n",
    "                               directed: bool = False,\n",
    "                               draw: bool = False):\n",
    "    \"\"\"\n",
    "    Generates a random graph, similarly to an Erdős-Rényi\n",
    "    graph, but enforcing that the resulting graph is conneted (in case of undirected graphs)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if directed:\n",
    "        G = nx.DiGraph()\n",
    "    else:\n",
    "        G = nx.Graph()\n",
    "    edges = combinations(range(num_of_nodes), 2)\n",
    "    G.add_nodes_from(range(num_of_nodes))\n",
    "\n",
    "    for _, node_edges in groupby(edges, key = lambda x: x[0]):\n",
    "        node_edges = list(node_edges)\n",
    "        random_edge = random.choice(node_edges)\n",
    "        if random.random() < 0.5:\n",
    "            random_edge = random_edge[::-1]\n",
    "        G.add_edge(*random_edge)\n",
    "        for e in node_edges:\n",
    "            if random.random() < completeness:\n",
    "                G.add_edge(*e)\n",
    "\n",
    "    for (u,v,w) in G.edges(data=True):\n",
    "        w['weight'] = random.randint(-5, 20)\n",
    "\n",
    "    if draw:\n",
    "        plt.figure(figsize=(10,6))\n",
    "        if directed:\n",
    "            # draw with edge weights\n",
    "            pos = nx.arf_layout(G)\n",
    "            nx.draw(G,pos, node_color='lightblue',\n",
    "                    with_labels=True,\n",
    "                    node_size=500,\n",
    "                    arrowsize=20,\n",
    "                    arrows=True)\n",
    "            labels = nx.get_edge_attributes(G,'weight')\n",
    "            nx.draw_networkx_edge_labels(G, pos,edge_labels=labels)\n",
    "\n",
    "        else:\n",
    "            nx.draw(G, node_color='lightblue',\n",
    "                with_labels=True,\n",
    "                node_size=500)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gnp_random_connected_graph(10, 0.2, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1.1 Minimum Spanning Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знайти підграф-дерево найменшої сумарної ваги ребер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstk = tree.minimum_spanning_tree(G, algorithm=\"kruskal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(mstk, node_color='lightblue',\n",
    "        with_labels=True,\n",
    "        node_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, node_color='lightblue',\n",
    "                with_labels=True,\n",
    "                node_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstk.edges().data(\"weight\"), sum(w for _, _, w in mstk.edges().data(\"weight\")), len(mstk.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Kruskal_algorithm(G: nx.Graph) -> nx.Graph:\n",
    "    tr: nx.Graph = nx.create_empty_copy(G)\n",
    "    n = len(G.nodes())\n",
    "    # print(n)\n",
    "    edges = G.edges().data(\"weight\")\n",
    "    edges = sorted(edges, key=lambda x: x[2])\n",
    "\n",
    "    for u, v, w in edges:\n",
    "        if not nx.has_path(tr, u, v):\n",
    "            tr.add_edge(u, v, weight=w)\n",
    "\n",
    "    return tr\n",
    "\n",
    "tr = Kruskal_algorithm(G)\n",
    "nx.draw(tr, node_color='lightblue',\n",
    "        with_labels=True,\n",
    "        node_size=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.edges().data(\"weight\"), sum(w for _, _, w in tr.edges().data(\"weight\")), len(tr.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Підсумок: алгоритм запрограмований дуже просто і примітивно, що, як побачим далі, сказується на швидкості виконання. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prim's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstp = tree.minimum_spanning_tree(G, algorithm=\"prim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(mstp, node_color='lightblue',\n",
    "        with_labels=True,\n",
    "        node_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstp.edges().data(\"weight\"), sum(w for _, _, w in mstp.edges().data(\"weight\")), len(mstp.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prim_algorithm(G: nx.Graph) -> nx.Graph:\n",
    "    tr = nx.create_empty_copy(G)\n",
    "\n",
    "    adj_list = dict.fromkeys(G.nodes(), None)\n",
    "    for (u, v, wt) in G.edges.data('weight'):\n",
    "        if not adj_list[u]:\n",
    "            adj_list[u] = {}\n",
    "        if not adj_list[v]:\n",
    "            adj_list[v] = {}\n",
    "        adj_list[u][v] = wt\n",
    "        adj_list[v][u] = wt\n",
    "    #     print(u, v, wt)\n",
    "    # print(adj_list)\n",
    "\n",
    "    v = list(G.nodes())[0]\n",
    "    pr_q = []\n",
    "    for to, w in adj_list[v].items():\n",
    "        heapq.heappush(pr_q, (w, to, v))\n",
    "    connected = set()\n",
    "    connected.add(v)\n",
    "    while pr_q != []:\n",
    "        weight, v, prev = heapq.heappop(pr_q)\n",
    "        if v in connected:\n",
    "            continue\n",
    "        connected.add(v)\n",
    "        tr.add_edge(prev, v, weight=weight)\n",
    "\n",
    "        for to, w in adj_list[v].items():\n",
    "            heapq.heappush(pr_q, (w, to, v))\n",
    "    return tr\n",
    "\n",
    "tr = Prim_algorithm(G)\n",
    "nx.draw(tr, node_color='lightblue',\n",
    "        with_labels=True,\n",
    "        node_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.edges().data(\"weight\"), sum(w for _, _, w in tr.edges().data(\"weight\")), len(tr.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Підсумок: алгоритм реалізований з використанням heapq. В швидкості виконання еквівалентний до реалізованих в networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gnp_random_connected_graph(10, 0.5, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bellman-Ford algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм Беллмана-Форда\n",
    "\n",
    "Алгоритм Беллмана-Форда використовується для знаходження найкоротших шляхів від однієї вихідної\n",
    "вершини до всіх інших вершин у графі. Він може працювати з графами, які мають ребра з від'ємною вагою.\n",
    "Алгоритм ітеративно оновлює відстані до вершин, проходячи через всі ребра графа, і перевіряє, чи\n",
    "можна покращити поточні відстані. Якщо після |V|-1 ітерацій (де |V| - кількість вершин) відстані \n",
    "ще можна покращити, це означає, що граф містить цикл з від'ємною вагою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred is a dictionary of predecessors, dist is a dictionary of distances\n",
    "try:\n",
    "    pred, dist = bellman_ford_predecessor_and_distance(G, 0)\n",
    "    for k, v in dist.items():\n",
    "        print(f\"Distance to {k}:\", v)\n",
    "except:\n",
    "    print(\"Negative cycle detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_ford_algorithm(G, start_node: int):\n",
    "    dist = dict.fromkeys(G.nodes(), float('inf'))\n",
    "    dist[start_node] = 0\n",
    "\n",
    "    for _ in range(len(G.nodes()) - 1):\n",
    "        for u, v, weight in G.edges(data=True):\n",
    "            if dist[u] != float('inf') and dist[u] + weight['weight'] < dist[v]:\n",
    "                dist[v] = dist[u] + weight['weight']\n",
    "\n",
    "    # check for negative weight cycles\n",
    "    for u, v, weight in G.edges(data=True):\n",
    "        if dist[u] != float('inf') and dist[u] + weight['weight'] < dist[v]:\n",
    "            return \"Negative cycle detected\"\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellman_ford_algorithm(G, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Підсумок експерименту з алгоритмом Беллмана-Форда\n",
    "\n",
    "У цьому експерименті ми дослідили алгоритм Беллмана-Форда для пошуку найкоротших шляхів від однієї вихідної вершини до всіх інших вершин у графі. Алгоритм ітеративно оновлює відстані до вершин, проходячи через всі ребра графа, і перевіряє, чи можна покращити поточні відстані.\n",
    "\n",
    "#### Результати\n",
    "- Алгоритм Беллмана-Форда успішно знаходить найкоротші шляхи у графах, які можуть містити ребра з від'ємною вагою.\n",
    "- Алгоритм виявляє наявність циклів з від'ємною вагою, що є важливою властивістю для багатьох застосувань.\n",
    "- Ми виміряли час виконання алгоритму для різної кількості вершин у графі та побудували графіки для порівняння продуктивності з іншими алгоритмами.\n",
    "\n",
    "#### Висновки\n",
    "- Алгоритм Беллмана-Форда є ефективним для знаходження найкоротших шляхів у графах з від'ємними вагами ребер, але його обчислювальна складність робить його менш придатним для дуже великих графів.\n",
    "- Для великих графів варто розглянути інші алгоритми або оптимізовані реалізації, такі як алгоритм Дейкстри або алгоритм Флойда-Воршалла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floyd-Warshall algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм Флойда-Воршалла\n",
    "\n",
    "Алгоритм Флойда-Воршалла використовується для знаходження найкоротших шляхів між усіма \n",
    "парами вершин у графі. Він працює з графами, які можуть мати як додатні, так і від'ємні\n",
    "ваги ребер, але не повинні містити циклів з від'ємною вагою. Алгоритм ітеративно покращує \n",
    "відстані між вершинами, використовуючи проміжні вершини, і гарантує, що після завершення\n",
    "роботи алгоритму відстані між усіма парами вершин будуть найкоротшими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred is a dictionary of predecessors, dist is a dictionary of distances dictionaries\n",
    "try:\n",
    "    pred, dist = floyd_warshall_predecessor_and_distance(G)\n",
    "    for k, v in dist.items():\n",
    "        print(f\"Distances with {k} source:\", dict(v))\n",
    "except:\n",
    "    print(\"Negative cycle detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floyd_warshall_algorithm(G):\n",
    "    n = len(G.nodes())\n",
    "    dist = [[float('inf') for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # set distance from node to itself to zero\n",
    "    for i in range(n):\n",
    "        dist[i][i] = 0\n",
    "\n",
    "    # set initial distances\n",
    "    for u, v, weight in G.edges(data=True):\n",
    "        dist[u][v] = weight['weight']\n",
    "\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                dist[i][j] = min(dist[i][j], (dist[i][k] + dist[k][j]))\n",
    "\n",
    "    # check for negative weight cycles\n",
    "    for i in range(n):\n",
    "        if dist[i][i] < 0:\n",
    "            return \"Negative cycle detected\"\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_w = floyd_warshall_algorithm(G)\n",
    "fl_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fl_w)):\n",
    "    print(f\"Distances with {i} source: { {k: dist for k, dist in zip(range(len(fl_w)), fl_w[i])} }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Підсумок експерименту з алгоритмом Флойда-Воршалла\n",
    "\n",
    "У цьому експерименті ми дослідили алгоритм Флойда-Воршалла для пошуку найкоротших шляхів між \n",
    "усіма парами вершин у графі. Алгоритм ітеративно покращує відстані між вершинами, використовуючи\n",
    "проміжні вершини.\n",
    "\n",
    "#### Результати\n",
    "- Алгоритм Флойда-Воршалла показав високу обчислювальну складність, особливо для великих графів.\n",
    "- Ми виміряли час виконання алгоритму для різної кількості вершин у графі та побудували графіки \n",
    "для порівняння продуктивності з іншими алгоритмами.\n",
    "\n",
    "#### Висновки\n",
    "- Алгоритм Флойда-Воршалла є ефективним для знаходження найкоротших шляхів між усіма парами \n",
    "вершин, але його обчислювальна складність робить його менш придатним для дуже великих графів.\n",
    "- Для великих графів варто розглянути інші алгоритми або оптимізовані реалізації, такі як ті,\n",
    " що надаються бібліотекою NetworkX.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful explanations\n",
    "### How to get list of edges for your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges()) # by default G.edges are EdgesView class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get edges with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(G.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(G.nodes())\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time measuring\n",
    "\n",
    "Read more on this: https://realpython.com/python-timer/\n",
    "\n",
    "Recall that you should measure times for 5, 10, 20, 50, 100, 200, 500 nodes 1000 times (and take mean of time taken for each node amount).\n",
    "\n",
    "Then you should build the plot for two algorithms (x - data size, y - mean time of execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ITERATIONS = 200\n",
    "num_nodes = [5, 10, 20, 50, 100, 200, 500]\n",
    "# TOTAL_NUM_OF_ITERATIONS = 40\n",
    "# num_nodes = [5, 10, 20, 50, 100, 200]\n",
    "completenesses = [0, 0.2, 0.4, 0.5, 0.75, 1]\n",
    "complete_size = len(completenesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum spanning tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_MST = {\n",
    "    \"nx_prim\": {\n",
    "        \"time\": {},\n",
    "        \"alg\": lambda g: tree.minimum_spanning_tree(g, algorithm=\"prim\")\n",
    "    },\n",
    "    \"my_prim\": {\n",
    "        \"time\": {},\n",
    "        \"alg\": lambda g: Prim_algorithm(g)\n",
    "    },\n",
    "    \"nx_krustal\": {\n",
    "        \"time\": {},\n",
    "        \"alg\": lambda g: tree.minimum_spanning_tree(g, algorithm=\"kruskal\")\n",
    "    },\n",
    "    \"my_krustal\": {\n",
    "        \"time\": {},\n",
    "        \"alg\": lambda g: Kruskal_algorithm(g)\n",
    "    },\n",
    "}\n",
    "for alg in measures_MST:\n",
    "    for n in num_nodes:\n",
    "        measures_MST[alg][\"time\"][n] = {}\n",
    "        measures_MST[alg][\"time\"][n] = {}\n",
    "        measures_MST[alg][\"time\"][n] = {}\n",
    "        measures_MST[alg][\"time\"][n] = {}\n",
    "        for comp in completenesses:\n",
    "            measures_MST[alg][\"time\"][n][comp] = {}\n",
    "            measures_MST[alg][\"time\"][n][comp] = {}\n",
    "            measures_MST[alg][\"time\"][n][comp] = {}\n",
    "            measures_MST[alg][\"time\"][n][comp] = {}\n",
    "\n",
    "            measures_MST[alg][\"time\"][n][comp][\"average\"] = 0\n",
    "            measures_MST[alg][\"time\"][n][comp][\"sum\"] = 0\n",
    "            measures_MST[alg][\"time\"][n][comp][\"iterations\"] = 0\n",
    "            measures_MST[alg][\"time\"][n][comp][\"min\"] = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in num_nodes:\n",
    "    for i in tqdm(range(NUM_OF_ITERATIONS), desc=str(n)):\n",
    "        comp = completenesses[i%complete_size]\n",
    "        # note that we should not measure time of graph creation\n",
    "        G = gnp_random_connected_graph(n, comp, False)\n",
    "\n",
    "        for k in measures_MST:\n",
    "            start = time.time()\n",
    "            gr = measures_MST[k][\"alg\"](G)\n",
    "            end = time.time()\n",
    "\n",
    "            measured = end - start\n",
    "            measures_MST[k][\"time\"][n][comp][\"sum\"] += measured\n",
    "            measures_MST[k][\"time\"][n][comp][\"min\"] = min(measured, measures_MST[k][\"time\"][n][comp][\"min\"])\n",
    "            measures_MST[k][\"time\"][n][comp][\"iterations\"] += 1\n",
    "\n",
    "    for k in measures_MST:\n",
    "        for comp in completenesses:\n",
    "            measures_MST[k][\"time\"][n][comp][\"average\"] = measures_MST[k][\"time\"][n][comp][\"sum\"] / measures_MST[k][\"time\"][n][comp][\"iterations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measures_SP = {\n",
    "#     'Bellman_Ford_nx': {\n",
    "#         'time': {},\n",
    "#         'alg': lambda g: bellman_ford_predecessor_and_distance(g, 0)\n",
    "#     },\n",
    "#     'Bellman_Ford': {\n",
    "#         'time': {},\n",
    "#         'alg': lambda g: bellman_ford_algorithm(g, 0)  # Your custom function\n",
    "#     },\n",
    "#     'Floyd_Warshall_nx': {\n",
    "#         'time': {},\n",
    "#         'alg': lambda g: floyd_warshall_predecessor_and_distance(g)\n",
    "#     },\n",
    "#     'Floyd_Warshall': {\n",
    "#         'time': {},\n",
    "#         'alg': lambda g: floyd_warshall_algorithm(g)   # Your custom function\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# for n in num_nodes:\n",
    "#     for k in measures_SP:\n",
    "#         measures_SP[k]['time'][n] = 0.0\n",
    "\n",
    "#     for _ in tqdm(range(NUM_OF_ITERATIONS), desc=f'Measuring for n={n}'):\n",
    "\n",
    "#         G = gnp_random_connected_graph(n, 0.5, True, True)  # Adjust completeness and directed as needed\n",
    "\n",
    "#         for k in measures_SP:\n",
    "#             start = time.time()\n",
    "#             try:\n",
    "#                 measures_SP[k]['alg'](G)\n",
    "#             except:\n",
    "#                 ...\n",
    "#             end = time.time()\n",
    "#             measures_SP[k]['time'][n] += (end - start)\n",
    "\n",
    "#     for k in measures_SP:\n",
    "#         measures_SP[k]['time'][n] /= NUM_OF_ITERATIONS\n",
    "\n",
    "# # Print results\n",
    "# for k in measures_SP:\n",
    "#     print(k, measures_SP[k]['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting time measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum spanning tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this if you don't want to measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measures_MST = {'nx_prim': {'time': {5: {0: {'average': 3.8462526658002066e-05,\n",
    "#      'sum': 0.0013077259063720703,\n",
    "#      'iterations': 34,\n",
    "#      'min': 1.8596649169921875e-05},\n",
    "#     0.2: {'average': 3.802075105554917e-05,\n",
    "#      'sum': 0.0012927055358886719,\n",
    "#      'iterations': 34,\n",
    "#      'min': 1.8358230590820312e-05},\n",
    "#     0.4: {'average': 5.0089576027610086e-05,\n",
    "#      'sum': 0.0016529560089111328,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.8596649169921875e-05},\n",
    "#     0.5: {'average': 5.7314381454930164e-05,\n",
    "#      'sum': 0.0018913745880126953,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.9073486328125e-05},\n",
    "#     0.75: {'average': 4.075512741551255e-05,\n",
    "#      'sum': 0.001344919204711914,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.0503997802734375e-05},\n",
    "#     1: {'average': 4.9085328073212594e-05,\n",
    "#      'sum': 0.0016198158264160156,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.1457672119140625e-05}},\n",
    "#    10: {0: {'average': 4.0271702934713923e-05,\n",
    "#      'sum': 0.0013692378997802734,\n",
    "#      'iterations': 34,\n",
    "#      'min': 2.9802322387695312e-05},\n",
    "#     0.2: {'average': 4.09238478716682e-05,\n",
    "#      'sum': 0.0013914108276367188,\n",
    "#      'iterations': 34,\n",
    "#      'min': 3.218650817871094e-05},\n",
    "#     0.4: {'average': 5.053751396410393e-05,\n",
    "#      'sum': 0.0016677379608154297,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.647804260253906e-05},\n",
    "#     0.5: {'average': 4.37245224461411e-05,\n",
    "#      'sum': 0.0014429092407226562,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.743171691894531e-05},\n",
    "#     0.75: {'average': 4.711295619155421e-05,\n",
    "#      'sum': 0.001554727554321289,\n",
    "#      'iterations': 33,\n",
    "#      'min': 4.076957702636719e-05},\n",
    "#     1: {'average': 5.7119311708392516e-05,\n",
    "#      'sum': 0.0018849372863769531,\n",
    "#      'iterations': 33,\n",
    "#      'min': 4.458427429199219e-05}},\n",
    "#    20: {0: {'average': 9.332684909596163e-05,\n",
    "#      'sum': 0.0031731128692626953,\n",
    "#      'iterations': 34,\n",
    "#      'min': 6.175041198730469e-05},\n",
    "#     0.2: {'average': 9.498175452737247e-05,\n",
    "#      'sum': 0.003229379653930664,\n",
    "#      'iterations': 34,\n",
    "#      'min': 7.915496826171875e-05},\n",
    "#     0.4: {'average': 0.00011366786378802675,\n",
    "#      'sum': 0.003751039505004883,\n",
    "#      'iterations': 33,\n",
    "#      'min': 9.703636169433594e-05},\n",
    "#     0.5: {'average': 0.0001362526055538293,\n",
    "#      'sum': 0.004496335983276367,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00010037422180175781},\n",
    "#     0.75: {'average': 0.00015102010784727153,\n",
    "#      'sum': 0.004983663558959961,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00011587142944335938},\n",
    "#     1: {'average': 0.00016045570373535156,\n",
    "#      'sum': 0.0052950382232666016,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00013399124145507812}},\n",
    "#    50: {0: {'average': 0.00020818149342256433,\n",
    "#      'sum': 0.0070781707763671875,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.00015664100646972656},\n",
    "#     0.2: {'average': 0.0003998419817756204,\n",
    "#      'sum': 0.013594627380371094,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0002837181091308594},\n",
    "#     0.4: {'average': 0.0005001227060953776,\n",
    "#      'sum': 0.01650404930114746,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00038504600524902344},\n",
    "#     0.5: {'average': 0.0006099108493689334,\n",
    "#      'sum': 0.020127058029174805,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0004210472106933594},\n",
    "#     0.75: {'average': 0.0007448557651404178,\n",
    "#      'sum': 0.02458024024963379,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0005223751068115234},\n",
    "#     1: {'average': 0.0008335041277336352,\n",
    "#      'sum': 0.02750563621520996,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0006437301635742188}},\n",
    "#    100: {0: {'average': 0.00035742451162899244,\n",
    "#      'sum': 0.012152433395385742,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0003094673156738281},\n",
    "#     0.2: {'average': 0.0009914636611938477,\n",
    "#      'sum': 0.03370976448059082,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0007984638214111328},\n",
    "#     0.4: {'average': 0.0016315272360137014,\n",
    "#      'sum': 0.05384039878845215,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0013582706451416016},\n",
    "#     0.5: {'average': 0.0018444783759839606,\n",
    "#      'sum': 0.0608677864074707,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0015988349914550781},\n",
    "#     0.75: {'average': 0.002644170414317738,\n",
    "#      'sum': 0.08725762367248535,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0021414756774902344},\n",
    "#     1: {'average': 0.0034134676962187796,\n",
    "#      'sum': 0.11264443397521973,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0029058456420898438}},\n",
    "#    200: {0: {'average': 0.0012692493550917681,\n",
    "#      'sum': 0.04315447807312012,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0005538463592529297},\n",
    "#     0.2: {'average': 0.006410346311681411,\n",
    "#      'sum': 0.21795177459716797,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0026886463165283203},\n",
    "#     0.4: {'average': 0.015311956405639648,\n",
    "#      'sum': 0.5052945613861084,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0046939849853515625},\n",
    "#     0.5: {'average': 0.01378070946895715,\n",
    "#      'sum': 0.45476341247558594,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0057375431060791016},\n",
    "#     0.75: {'average': 0.020542086976947205,\n",
    "#      'sum': 0.6778888702392578,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.008195877075195312},\n",
    "#     1: {'average': 0.03320865920095733,\n",
    "#      'sum': 1.0958857536315918,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.010470390319824219}},\n",
    "#    500: {0: {'average': 0.003533482551574707,\n",
    "#      'sum': 0.12013840675354004,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0015759468078613281},\n",
    "#     0.2: {'average': 0.05617820515352137,\n",
    "#      'sum': 1.9100589752197266,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.01718592643737793},\n",
    "#     0.4: {'average': 0.15652055451364227,\n",
    "#      'sum': 5.165178298950195,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.03608560562133789},\n",
    "#     0.5: {'average': 0.13419670769662567,\n",
    "#      'sum': 4.4284913539886475,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.04692697525024414},\n",
    "#     0.75: {'average': 0.23791469949664493,\n",
    "#      'sum': 7.851185083389282,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.06545209884643555},\n",
    "#     1: {'average': 0.3070666356520219,\n",
    "#      'sum': 10.133198976516724,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.09843635559082031}}},\n",
    "#   'alg': None},\n",
    "#  'my_prim': {'time': {5: {0: {'average': 3.081910750445197e-05,\n",
    "#      'sum': 0.0010478496551513672,\n",
    "#      'iterations': 34,\n",
    "#      'min': 1.5735626220703125e-05},\n",
    "#     0.2: {'average': 3.154137555290671e-05,\n",
    "#      'sum': 0.0010724067687988281,\n",
    "#      'iterations': 34,\n",
    "#      'min': 1.5974044799804688e-05},\n",
    "#     0.4: {'average': 3.5777236476089016e-05,\n",
    "#      'sum': 0.0011806488037109375,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.5974044799804688e-05},\n",
    "#     0.5: {'average': 3.390601187041312e-05,\n",
    "#      'sum': 0.0011188983917236328,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.7404556274414062e-05},\n",
    "#     0.75: {'average': 3.553159309156013e-05,\n",
    "#      'sum': 0.0011725425720214844,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.8596649169921875e-05},\n",
    "#     1: {'average': 3.699100378787879e-05,\n",
    "#      'sum': 0.001220703125,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.002716064453125e-05}},\n",
    "#    10: {0: {'average': 3.092429217170267e-05,\n",
    "#      'sum': 0.0010514259338378906,\n",
    "#      'iterations': 34,\n",
    "#      'min': 2.6464462280273438e-05},\n",
    "#     0.2: {'average': 3.879210528205423e-05,\n",
    "#      'sum': 0.0013189315795898438,\n",
    "#      'iterations': 34,\n",
    "#      'min': 3.123283386230469e-05},\n",
    "#     0.4: {'average': 4.331993334221117e-05,\n",
    "#      'sum': 0.0014295578002929688,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.552436828613281e-05},\n",
    "#     0.5: {'average': 4.659999500621449e-05,\n",
    "#      'sum': 0.0015377998352050781,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.8623809814453125e-05},\n",
    "#     0.75: {'average': 6.323872190533262e-05,\n",
    "#      'sum': 0.0020868778228759766,\n",
    "#      'iterations': 33,\n",
    "#      'min': 4.5299530029296875e-05},\n",
    "#     1: {'average': 6.242954369747278e-05,\n",
    "#      'sum': 0.0020601749420166016,\n",
    "#      'iterations': 33,\n",
    "#      'min': 5.507469177246094e-05}},\n",
    "#    20: {0: {'average': 6.636451272403493e-05,\n",
    "#      'sum': 0.0022563934326171875,\n",
    "#      'iterations': 34,\n",
    "#      'min': 5.745887756347656e-05},\n",
    "#     0.2: {'average': 0.0001061102923224954,\n",
    "#      'sum': 0.0036077499389648438,\n",
    "#      'iterations': 34,\n",
    "#      'min': 8.320808410644531e-05},\n",
    "#     0.4: {'average': 0.0001453558603922526,\n",
    "#      'sum': 0.004796743392944336,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0001232624053955078},\n",
    "#     0.5: {'average': 0.0001650795792088364,\n",
    "#      'sum': 0.0054476261138916016,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00013017654418945312},\n",
    "#     0.75: {'average': 0.00022122354218454072,\n",
    "#      'sum': 0.007300376892089844,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00017333030700683594},\n",
    "#     1: {'average': 0.0002553968718557647,\n",
    "#      'sum': 0.008428096771240234,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0002193450927734375}},\n",
    "#    50: {0: {'average': 0.0001717244877534754,\n",
    "#      'sum': 0.005838632583618164,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0001289844512939453},\n",
    "#     0.2: {'average': 0.000503084238837747,\n",
    "#      'sum': 0.0171048641204834,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.00037026405334472656},\n",
    "#     0.4: {'average': 0.0008184115091959635,\n",
    "#      'sum': 0.027007579803466797,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0006415843963623047},\n",
    "#     0.5: {'average': 0.0010041179078997989,\n",
    "#      'sum': 0.03313589096069336,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0007598400115966797},\n",
    "#     0.75: {'average': 0.0014719096097079191,\n",
    "#      'sum': 0.04857301712036133,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0010356903076171875},\n",
    "#     1: {'average': 0.001897645719123609,\n",
    "#      'sum': 0.0626223087310791,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0013689994812011719}},\n",
    "#    100: {0: {'average': 0.00030912371242747586,\n",
    "#      'sum': 0.01051020622253418,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.00026607513427734375},\n",
    "#     0.2: {'average': 0.0016634885002585018,\n",
    "#      'sum': 0.05655860900878906,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0014073848724365234},\n",
    "#     0.4: {'average': 0.003221121701327237,\n",
    "#      'sum': 0.10629701614379883,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0025856494903564453},\n",
    "#     0.5: {'average': 0.004090908801916874,\n",
    "#      'sum': 0.13499999046325684,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0034995079040527344},\n",
    "#     0.75: {'average': 0.006136793078798236,\n",
    "#      'sum': 0.2025141716003418,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.005171298980712891},\n",
    "#     1: {'average': 0.007955717317985765,\n",
    "#      'sum': 0.2625386714935303,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.006973743438720703}},\n",
    "#    200: {0: {'average': 0.001129150390625,\n",
    "#      'sum': 0.03839111328125,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0004978179931640625},\n",
    "#     0.2: {'average': 0.012911445954266717,\n",
    "#      'sum': 0.43898916244506836,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.005784511566162109},\n",
    "#     0.4: {'average': 0.02556655623696067,\n",
    "#      'sum': 0.8436963558197021,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.01151132583618164},\n",
    "#     0.5: {'average': 0.03569364547729492,\n",
    "#      'sum': 1.1778903007507324,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.014589071273803711},\n",
    "#     0.75: {'average': 0.0534596298680161,\n",
    "#      'sum': 1.7641677856445312,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.021439313888549805},\n",
    "#     1: {'average': 0.07000030893268007,\n",
    "#      'sum': 2.3100101947784424,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.02736520767211914}},\n",
    "#    500: {0: {'average': 0.003358336055980009,\n",
    "#      'sum': 0.11418342590332031,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0014662742614746094},\n",
    "#     0.2: {'average': 0.1069269811405855,\n",
    "#      'sum': 3.6355173587799072,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.043161630630493164},\n",
    "#     0.4: {'average': 0.23449481617320667,\n",
    "#      'sum': 7.73832893371582,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.09762263298034668},\n",
    "#     0.5: {'average': 0.22829693013971503,\n",
    "#      'sum': 7.533798694610596,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.11769914627075195},\n",
    "#     0.75: {'average': 0.47164553584474506,\n",
    "#      'sum': 15.564302682876587,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.1847522258758545},\n",
    "#     1: {'average': 0.5788431384346702,\n",
    "#      'sum': 19.101823568344116,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.2623775005340576}}},\n",
    "#   'alg': None},\n",
    "#  'nx_krustal': {'time': {5: {0: {'average': 4.099397098316866e-05,\n",
    "#      'sum': 0.0013937950134277344,\n",
    "#      'iterations': 34,\n",
    "#      'min': 2.1219253540039062e-05},\n",
    "#     0.2: {'average': 4.265588872572955e-05,\n",
    "#      'sum': 0.0014503002166748047,\n",
    "#      'iterations': 34,\n",
    "#      'min': 2.1219253540039062e-05},\n",
    "#     0.4: {'average': 4.466374715169271e-05,\n",
    "#      'sum': 0.0014739036560058594,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.2649765014648438e-05},\n",
    "#     0.5: {'average': 4.495273936878551e-05,\n",
    "#      'sum': 0.0014834403991699219,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.3126602172851562e-05},\n",
    "#     0.75: {'average': 4.480101845481179e-05,\n",
    "#      'sum': 0.001478433609008789,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.4318695068359375e-05},\n",
    "#     1: {'average': 4.7792087901722304e-05,\n",
    "#      'sum': 0.001577138900756836,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.5033950805664062e-05}},\n",
    "#    10: {0: {'average': 4.323791055118336e-05,\n",
    "#      'sum': 0.0014700889587402344,\n",
    "#      'iterations': 34,\n",
    "#      'min': 3.600120544433594e-05},\n",
    "#     0.2: {'average': 5.0551751080681296e-05,\n",
    "#      'sum': 0.001718759536743164,\n",
    "#      'iterations': 34,\n",
    "#      'min': 4.00543212890625e-05},\n",
    "#     0.4: {'average': 5.1787405303030304e-05,\n",
    "#      'sum': 0.001708984375,\n",
    "#      'iterations': 33,\n",
    "#      'min': 4.363059997558594e-05},\n",
    "#     0.5: {'average': 5.4648428252249054e-05,\n",
    "#      'sum': 0.0018033981323242188,\n",
    "#      'iterations': 33,\n",
    "#      'min': 4.673004150390625e-05},\n",
    "#     0.75: {'average': 6.0579993508078836e-05,\n",
    "#      'sum': 0.0019991397857666016,\n",
    "#      'iterations': 33,\n",
    "#      'min': 5.14984130859375e-05},\n",
    "#     1: {'average': 6.544951236609256e-05,\n",
    "#      'sum': 0.0021598339080810547,\n",
    "#      'iterations': 33,\n",
    "#      'min': 5.698204040527344e-05}},\n",
    "#    20: {0: {'average': 8.958227494183709e-05,\n",
    "#      'sum': 0.003045797348022461,\n",
    "#      'iterations': 34,\n",
    "#      'min': 7.2479248046875e-05},\n",
    "#     0.2: {'average': 0.00011803823358872357,\n",
    "#      'sum': 0.0040132999420166016,\n",
    "#      'iterations': 34,\n",
    "#      'min': 9.942054748535156e-05},\n",
    "#     0.4: {'average': 0.00015249396815444484,\n",
    "#      'sum': 0.00503230094909668,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0001239776611328125},\n",
    "#     0.5: {'average': 0.0001603617812647964,\n",
    "#      'sum': 0.005291938781738281,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0001289844512939453},\n",
    "#     0.75: {'average': 0.00019035917339902935,\n",
    "#      'sum': 0.006281852722167969,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0001575946807861328},\n",
    "#     1: {'average': 0.00022253845677231297,\n",
    "#      'sum': 0.007343769073486328,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00019407272338867188}},\n",
    "#    50: {0: {'average': 0.00023502462050494025,\n",
    "#      'sum': 0.007990837097167969,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0001773834228515625},\n",
    "#     0.2: {'average': 0.0004634997423957376,\n",
    "#      'sum': 0.015758991241455078,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0003418922424316406},\n",
    "#     0.4: {'average': 0.0006695443933660334,\n",
    "#      'sum': 0.0220949649810791,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0004987716674804688},\n",
    "#     0.5: {'average': 0.0007667324759743431,\n",
    "#      'sum': 0.02530217170715332,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0005931854248046875},\n",
    "#     0.75: {'average': 0.0010756145824085581,\n",
    "#      'sum': 0.03549528121948242,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0007715225219726562},\n",
    "#     1: {'average': 0.0012776851654052734,\n",
    "#      'sum': 0.04216361045837402,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0009403228759765625}},\n",
    "#    100: {0: {'average': 0.00040449114406810086,\n",
    "#      'sum': 0.01375269889831543,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0003592967987060547},\n",
    "#     0.2: {'average': 0.0012679240282844095,\n",
    "#      'sum': 0.04310941696166992,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0010623931884765625},\n",
    "#     0.4: {'average': 0.0021575075207334576,\n",
    "#      'sum': 0.0711977481842041,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0018045902252197266},\n",
    "#     0.5: {'average': 0.0026878226887096057,\n",
    "#      'sum': 0.08869814872741699,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0022475719451904297},\n",
    "#     0.75: {'average': 0.004013964624115915,\n",
    "#      'sum': 0.1324608325958252,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0032677650451660156},\n",
    "#     1: {'average': 0.0050133286100445375,\n",
    "#      'sum': 0.16543984413146973,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.004239320755004883}},\n",
    "#    200: {0: {'average': 0.0015453871558694279,\n",
    "#      'sum': 0.05254316329956055,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0006518363952636719},\n",
    "#     0.2: {'average': 0.009036912637598375,\n",
    "#      'sum': 0.3072550296783447,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.003757953643798828},\n",
    "#     0.4: {'average': 0.020691286433826794,\n",
    "#      'sum': 0.6828124523162842,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.006996870040893555},\n",
    "#     0.5: {'average': 0.020028461109508167,\n",
    "#      'sum': 0.6609392166137695,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.008536577224731445},\n",
    "#     0.75: {'average': 0.027316830374977806,\n",
    "#      'sum': 0.9014554023742676,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.01236867904663086},\n",
    "#     1: {'average': 0.06960853663357822,\n",
    "#      'sum': 2.297081708908081,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.016750097274780273}},\n",
    "#    500: {0: {'average': 0.004215310601627126,\n",
    "#      'sum': 0.14332056045532227,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0018925666809082031},\n",
    "#     0.2: {'average': 0.056694963399101704,\n",
    "#      'sum': 1.927628755569458,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.023853063583374023},\n",
    "#     0.4: {'average': 0.1391498175534335,\n",
    "#      'sum': 4.591943979263306,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.05631256103515625},\n",
    "#     0.5: {'average': 0.17151183793039032,\n",
    "#      'sum': 5.659890651702881,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.06832242012023926},\n",
    "#     0.75: {'average': 0.31300471045754175,\n",
    "#      'sum': 10.329155445098877,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.09353423118591309},\n",
    "#     1: {'average': 0.365731651132757,\n",
    "#      'sum': 12.069144487380981,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.14484906196594238}}},\n",
    "#   'alg': None},\n",
    "#  'my_krustal': {'time': {5: {0: {'average': 5.140024072983686e-05,\n",
    "#      'sum': 0.0017476081848144531,\n",
    "#      'iterations': 34,\n",
    "#      'min': 2.6702880859375e-05},\n",
    "#     0.2: {'average': 5.987111259909237e-05,\n",
    "#      'sum': 0.0020356178283691406,\n",
    "#      'iterations': 34,\n",
    "#      'min': 2.8133392333984375e-05},\n",
    "#     0.4: {'average': 6.763140360514323e-05,\n",
    "#      'sum': 0.0022318363189697266,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.24249267578125e-05},\n",
    "#     0.5: {'average': 7.229140310576467e-05,\n",
    "#      'sum': 0.0023856163024902344,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.1948089599609375e-05},\n",
    "#     0.75: {'average': 7.53619454123757e-05,\n",
    "#      'sum': 0.0024869441986083984,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.8623809814453125e-05},\n",
    "#     1: {'average': 8.624250238591975e-05,\n",
    "#      'sum': 0.0028460025787353516,\n",
    "#      'iterations': 33,\n",
    "#      'min': 4.506111145019531e-05}},\n",
    "#    10: {0: {'average': 6.082478691549862e-05,\n",
    "#      'sum': 0.002068042755126953,\n",
    "#      'iterations': 34,\n",
    "#      'min': 4.9114227294921875e-05},\n",
    "#     0.2: {'average': 9.38106985653148e-05,\n",
    "#      'sum': 0.003189563751220703,\n",
    "#      'iterations': 34,\n",
    "#      'min': 6.866455078125e-05},\n",
    "#     0.4: {'average': 0.00011965000268184778,\n",
    "#      'sum': 0.0039484500885009766,\n",
    "#      'iterations': 33,\n",
    "#      'min': 8.988380432128906e-05},\n",
    "#     0.5: {'average': 0.00013896913239450166,\n",
    "#      'sum': 0.004585981369018555,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00010895729064941406},\n",
    "#     0.75: {'average': 0.0001700430205374053,\n",
    "#      'sum': 0.005611419677734375,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00013327598571777344},\n",
    "#     1: {'average': 0.00020360224174730706,\n",
    "#      'sum': 0.006718873977661133,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00017499923706054688}},\n",
    "#    20: {0: {'average': 0.00013782697565415327,\n",
    "#      'sum': 0.004686117172241211,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.00010848045349121094},\n",
    "#     0.2: {'average': 0.0003530207802267636,\n",
    "#      'sum': 0.012002706527709961,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.00026226043701171875},\n",
    "#     0.4: {'average': 0.000548030390883937,\n",
    "#      'sum': 0.018085002899169922,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0004277229309082031},\n",
    "#     0.5: {'average': 0.0006578618829900569,\n",
    "#      'sum': 0.021709442138671875,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0005366802215576172},\n",
    "#     0.75: {'average': 0.0009032740737452651,\n",
    "#      'sum': 0.02980804443359375,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0007271766662597656},\n",
    "#     1: {'average': 0.001135226451989376,\n",
    "#      'sum': 0.037462472915649414,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0009355545043945312}},\n",
    "#    50: {0: {'average': 0.00037867181441363166,\n",
    "#      'sum': 0.012874841690063477,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0002846717834472656},\n",
    "#     0.2: {'average': 0.002997230080997243,\n",
    "#      'sum': 0.10190582275390625,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0020542144775390625},\n",
    "#     0.4: {'average': 0.005634112791581588,\n",
    "#      'sum': 0.18592572212219238,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0038862228393554688},\n",
    "#     0.5: {'average': 0.0067054358395663176,\n",
    "#      'sum': 0.22127938270568848,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00501251220703125},\n",
    "#     0.75: {'average': 0.009795803012269916,\n",
    "#      'sum': 0.3232614994049072,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.00652313232421875},\n",
    "#     1: {'average': 0.012740915471857244,\n",
    "#      'sum': 0.42045021057128906,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.0076236724853515625}},\n",
    "#    100: {0: {'average': 0.0006697528502520393,\n",
    "#      'sum': 0.022771596908569336,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0006012916564941406},\n",
    "#     0.2: {'average': 0.015810096965116614,\n",
    "#      'sum': 0.5375432968139648,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.012006044387817383},\n",
    "#     0.4: {'average': 0.03210220192417954,\n",
    "#      'sum': 1.0593726634979248,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.023702383041381836},\n",
    "#     0.5: {'average': 0.040089137626416756,\n",
    "#      'sum': 1.322941541671753,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.028064489364624023},\n",
    "#     0.75: {'average': 0.054763656674009384,\n",
    "#      'sum': 1.8072006702423096,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.04135942459106445},\n",
    "#     1: {'average': 0.06815955133149118,\n",
    "#      'sum': 2.249265193939209,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.04848670959472656}},\n",
    "#    200: {0: {'average': 0.0027245002634385053,\n",
    "#      'sum': 0.09263300895690918,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0010917186737060547},\n",
    "#     0.2: {'average': 0.2108097146539127,\n",
    "#      'sum': 7.167530298233032,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.06713032722473145},\n",
    "#     0.4: {'average': 0.3648092674486565,\n",
    "#      'sum': 12.038705825805664,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.1320352554321289},\n",
    "#     0.5: {'average': 0.3851672519337047,\n",
    "#      'sum': 12.710519313812256,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.1611030101776123},\n",
    "#     0.75: {'average': 0.6114368944457083,\n",
    "#      'sum': 20.177417516708374,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.19933199882507324},\n",
    "#     1: {'average': 0.7677293835264264,\n",
    "#      'sum': 25.33506965637207,\n",
    "#      'iterations': 33,\n",
    "#      'min': 0.28412318229675293}},\n",
    "#    500: {0: {'average': 0.007536432322333841,\n",
    "#      'sum': 0.2562386989593506,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.0031354427337646484},\n",
    "#     0.2: {'average': 3.227950467782862,\n",
    "#      'sum': 109.75031590461731,\n",
    "#      'iterations': 34,\n",
    "#      'min': 0.9043302536010742},\n",
    "#     0.4: {'average': 3.9670277147582085,\n",
    "#      'sum': 130.91191458702087,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.6580321788787842},\n",
    "#     0.5: {'average': 4.11928002762072,\n",
    "#      'sum': 135.93624091148376,\n",
    "#      'iterations': 33,\n",
    "#      'min': 1.9798822402954102},\n",
    "#     0.75: {'average': 7.98817313078678,\n",
    "#      'sum': 263.60971331596375,\n",
    "#      'iterations': 33,\n",
    "#      'min': 2.338313579559326},\n",
    "#     1: {'average': 7.762058026862867,\n",
    "#      'sum': 256.1479148864746,\n",
    "#      'iterations': 33,\n",
    "#      'min': 3.1518876552581787}}},\n",
    "#   'alg': None}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графік швидкості середнього та мінімального часу виконання кожного алгоритму в залежності від кількості вершин та заповненості графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the measures_MST is stored in a variable called 'measures_MST'\n",
    "\n",
    "algorithms = measures_MST.keys()\n",
    "completeness_levels = [0, 0.2, 0.4, 0.5, 0.75, 1]\n",
    "colors = plt.cm.tab10.colors  # Using a colormap with distinct colors\n",
    "\n",
    "for alg in algorithms:\n",
    "    alg_data = measures_MST[alg]['time']\n",
    "    ns = sorted(alg_data.keys())\n",
    "\n",
    "    # Prepare measures_MST for average and min times\n",
    "    avg_times = {comp: [] for comp in completeness_levels}\n",
    "    min_times = {comp: [] for comp in completeness_levels}\n",
    "    for n in ns:\n",
    "        for comp in completeness_levels:\n",
    "            avg_times[comp].append(alg_data[n][comp]['average'])\n",
    "            min_times[comp].append(alg_data[n][comp]['min'])\n",
    "\n",
    "    # Plot average times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, comp in enumerate(completeness_levels):\n",
    "        plt.plot(ns, avg_times[comp], marker='o', linestyle='-', color=colors[i], label=f'Comp {comp}')\n",
    "    plt.xlabel('Number of Nodes (n)')\n",
    "    plt.ylabel('Average Time (seconds)')\n",
    "    plt.title(f'Average Time vs Number of Nodes for {alg}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(ns, labels=[str(n) for n in ns])\n",
    "    plt.show()\n",
    "\n",
    "    # Plot min times\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, comp in enumerate(completeness_levels):\n",
    "        plt.plot(ns, min_times[comp], marker='s', linestyle='--', color=colors[i], label=f'Comp {comp}')\n",
    "    plt.xlabel('Number of Nodes (n)')\n",
    "    plt.ylabel('Minimum Time (seconds)')\n",
    "    plt.title(f'Minimum Time vs Number of Nodes for {alg}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(ns, labels=[str(n) for n in ns])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Кількість вершин є вирішальним фактором, а не заповненість графу.\n",
    " \n",
    "> Є суттєва різниця лише між заповненістю, що == 0, та != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Час виконання всіх алгоритмів накладений на один графік для різних заповненостей графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For plotting, we will exclude 'my_krustal' since its times ruin the scale.\n",
    "algorithms_to_plot = [alg for alg in measures_MST.keys() if alg != 'my_krustal']\n",
    "\n",
    "# Extract node counts and completeness levels from one algorithm's data (they are assumed consistent).\n",
    "example_alg = list(measures_MST.keys())[0]\n",
    "node_counts = sorted(measures_MST[example_alg]['time'].keys())\n",
    "completeness_levels = sorted(measures_MST[example_alg]['time'][node_counts[0]].keys())\n",
    "\n",
    "# Define a color mapping for the remaining algorithms.\n",
    "colors = {\n",
    "    'nx_prim': 'blue',\n",
    "    'my_prim': 'green',\n",
    "    'nx_krustal': 'red'\n",
    "}\n",
    "\n",
    "# Create one figure with subplots (2 rows x 3 columns, one per completeness level).\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop over each completeness level and plot both average and minimum times.\n",
    "for i, comp in enumerate(completeness_levels):\n",
    "    ax = axs[i]\n",
    "    for alg in algorithms_to_plot:\n",
    "        # Gather average and minimum times for all node counts for the current completeness.\n",
    "        avg_times = [\n",
    "            measures_MST[alg]['time'][n][comp]['average'] for n in node_counts\n",
    "        ]\n",
    "        min_times = [\n",
    "            measures_MST[alg]['time'][n][comp]['min'] for n in node_counts\n",
    "        ]\n",
    "        # Plot average times: solid line with circle markers.\n",
    "        ax.plot(node_counts, avg_times, marker='o', linestyle='-', color=colors.get(alg),\n",
    "                label=f\"{alg} avg\")\n",
    "        # Plot minimum times: dashed line with cross markers.\n",
    "        ax.plot(node_counts, min_times, marker='x', linestyle='--', color=colors.get(alg),\n",
    "                label=f\"{alg} min\")\n",
    "\n",
    "    ax.set_title(f\"Completeness = {comp}\")\n",
    "    ax.set_xlabel(\"Number of Nodes\")\n",
    "    ax.set_ylabel(\"Time (s)\")\n",
    "    ax.legend(fontsize='small', loc='upper left')\n",
    "\n",
    "fig.suptitle(\"MST Computation Times (Average & Minimum, Excluding 'my_krustal')\", fontsize=16)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порівняння алгоритмів на різних заповненостях графів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We exclude 'my_krustal' since its times skew the scale.\n",
    "algorithms_to_plot = [alg for alg in measures_MST.keys()]\n",
    "\n",
    "# Extract sorted node counts (n) and completeness levels.\n",
    "example_alg = list(measures_MST.keys())[0]\n",
    "node_counts = sorted(measures_MST[example_alg]['time'].keys())  # e.g. [5, 10, 20, 50, 100, 200]\n",
    "completeness_levels = sorted(measures_MST[example_alg]['time'][node_counts[0]].keys())  # e.g. [0, 0.2, 0.4, 0.5, 0.75, 1]\n",
    "\n",
    "# Define a color for each algorithm.\n",
    "colors = {\n",
    "    'nx_prim': 'blue',\n",
    "    'my_prim': 'green',\n",
    "    'nx_krustal': 'red'\n",
    "}\n",
    "\n",
    "# Create one subplot per node count (2 rows x 3 columns if there are 6 node counts).\n",
    "# Note: sharex is kept for consistent x-axis, but sharey is set to False so that each subplot scales independently.\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10), sharex=True, sharey=False)\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop over each node count and create its subplot.\n",
    "for i, n in enumerate(node_counts):\n",
    "    ax = axs[i]\n",
    "    # For each algorithm, extract the average and minimum times as a function of completeness.\n",
    "    for alg in algorithms_to_plot:\n",
    "        avg_times = [measures_MST[alg]['time'][n][comp]['average'] for comp in completeness_levels]\n",
    "        min_times = [measures_MST[alg]['time'][n][comp]['min'] for comp in completeness_levels]\n",
    "        # Plot average times: solid line with circle markers.\n",
    "        ax.plot(completeness_levels, avg_times, marker='o', linestyle='-', color=colors.get(alg),\n",
    "                label=f\"{alg} avg\")\n",
    "        # Plot minimum times: dashed line with cross markers.\n",
    "        ax.plot(completeness_levels, min_times, marker='x', linestyle='--', color=colors.get(alg),\n",
    "                label=f\"{alg} min\")\n",
    "\n",
    "    ax.set_title(f\"n = {n}\")\n",
    "    ax.set_xlabel(\"Completeness\")\n",
    "    ax.set_ylabel(\"Time (s)\")\n",
    "    ax.legend(fontsize='small', loc='upper left')\n",
    "\n",
    "fig.suptitle(\"MST Computation Times vs. Completeness for Each Node Count\\n(Excluding 'my_krustal')\", fontsize=16)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без my_kruskal's, бо він занадто повільний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We exclude 'my_krustal' since its times skew the scale.\n",
    "algorithms_to_plot = [alg for alg in measures_MST.keys() if alg != 'my_krustal']\n",
    "\n",
    "# Extract sorted node counts (n) and completeness levels.\n",
    "example_alg = list(measures_MST.keys())[0]\n",
    "node_counts = sorted(measures_MST[example_alg]['time'].keys())  # e.g. [5, 10, 20, 50, 100, 200]\n",
    "completeness_levels = sorted(measures_MST[example_alg]['time'][node_counts[0]].keys())  # e.g. [0, 0.2, 0.4, 0.5, 0.75, 1]\n",
    "\n",
    "# Define a color for each algorithm.\n",
    "colors = {\n",
    "    'nx_prim': 'blue',\n",
    "    'my_prim': 'green',\n",
    "    'nx_krustal': 'red'\n",
    "}\n",
    "\n",
    "# Create one subplot per node count (2 rows x 3 columns if there are 6 node counts).\n",
    "# Note: sharex is kept for consistent x-axis, but sharey is set to False so that each subplot scales independently.\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 10), sharex=True, sharey=False)\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop over each node count and create its subplot.\n",
    "for i, n in enumerate(node_counts):\n",
    "    ax = axs[i]\n",
    "    # For each algorithm, extract the average and minimum times as a function of completeness.\n",
    "    for alg in algorithms_to_plot:\n",
    "        avg_times = [measures_MST[alg]['time'][n][comp]['average'] for comp in completeness_levels]\n",
    "        min_times = [measures_MST[alg]['time'][n][comp]['min'] for comp in completeness_levels]\n",
    "        # Plot average times: solid line with circle markers.\n",
    "        ax.plot(completeness_levels, avg_times, marker='o', linestyle='-', color=colors.get(alg),\n",
    "                label=f\"{alg} avg\")\n",
    "        # Plot minimum times: dashed line with cross markers.\n",
    "        ax.plot(completeness_levels, min_times, marker='x', linestyle='--', color=colors.get(alg),\n",
    "                label=f\"{alg} min\")\n",
    "\n",
    "    ax.set_title(f\"n = {n}\")\n",
    "    ax.set_xlabel(\"Completeness\")\n",
    "    ax.set_ylabel(\"Time (s)\")\n",
    "    ax.legend(fontsize='small', loc='upper left')\n",
    "\n",
    "fig.suptitle(\"MST Computation Times vs. Completeness for Each Node Count\\n(Excluding 'my_krustal')\", fontsize=16)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Висновок: нами реалізований алгоритм Крускала виділяється своєю повільністю через просту реалізацію. Алгоритм Прима реалізований нами був реалізований складніше і в швидкості виконання тримається на рівні реалізованих у бібліотеці  networkx. \n",
    "\n",
    "Алгоритм Крускала реалізований в networkx є повільнішим за алгоритм Прима\n",
    "\n",
    "При малих кількостях вершин(до 50) алгоритми дуже близькі в швидкості виконання і який впорається швидше залежить від випадку. При малих кількостях вершин та малій заповненості нами реалізований алгоритм Прима виконується швидше, ніж реалізовані в бібліотеці скоріш за все через велику кількість підготовки до виконання алгоритму, а в нашому підготовки менше. \n",
    "\n",
    "при n >= 10 та повному графі nx_prim виконується найскоріше, залишаючи my_prim та nx_kruskal змагатись за перше місце. Вони змагаються до 50 вершин, а далі чітко видно, що my_prim повільніший за nx_kruskal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# running all 4 algorithms takes too much time, thats why here compared only my\n",
    "# implementations of Bellman-Ford and Floyd-Warshall algorithms.\n",
    "measures_SP = {\n",
    "    'Bellman_Ford': {5: 4.17020320892334e-05,\n",
    "                     10: 0.00016554474830627442,\n",
    "                     20: 0.0008623614311218261,\n",
    "                     50: 0.01302280068397522,\n",
    "                     100: 0.09400515389442445,\n",
    "                     200: 0.7613448793888092},\n",
    "    'Floyd_Warshall': {5: 5.112791061401367e-05,\n",
    "                       10: 0.00022662305831909179,\n",
    "                       20: 0.0018492567539215088,\n",
    "                       50: 0.0282816801071167,\n",
    "                       100: 0.21050556206703186,\n",
    "                       200: 1.7686292695999146}\n",
    "}\n",
    "\n",
    "# Extracting data for plotting\n",
    "nodes = list(measures_SP['Bellman_Ford'].keys())\n",
    "bellman_ford_times = list(measures_SP['Bellman_Ford'].values())\n",
    "floyd_warshall_times = list(measures_SP['Floyd_Warshall'].values())\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(nodes, bellman_ford_times, marker='o', label='Bellman-Ford')\n",
    "plt.plot(nodes, floyd_warshall_times, marker='s', label='Floyd-Warshall')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Performance Comparison of Bellman-Ford and Floyd-Warshall Algorithms')\n",
    "plt.xlabel('Number of Nodes')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn package\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General idea\n",
    "\n",
    "#### You are expected to write a quite simple, yet good core logic of decision tree classifier class. Additionaly, you need to test your results and write down a report on what you've done, which principles used and explain the general process.\n",
    "\n",
    "#### Hopefully, you have already learned what is decision tree classifier and how it work. For better understanding, and in case if something is still unclear for you, here are some useful links on basics of DTC:\n",
    "- https://www.youtube.com/watch?v=ZVR2Way4nwQ\n",
    "- https://towardsdatascience.com/decision-tree-classifier-explained-a-visual-guide-with-code-examples-for-beginners-7c863f06a71e\n",
    "- https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775\n",
    "- https://www.kaggle.com/code/prashant111/decision-tree-classifier-tutorial\n",
    "- https://towardsdatascience.com/decision-tree-classifier-explained-in-real-life-picking-a-vacation-destination-6226b2b6057\n",
    "\n",
    "#### Also, for those interested to learn more about machine learning and particulary Desicion Trees - here is a great course on Coursera (you may be interested in the whole course or just this particular week):\n",
    "- https://www.coursera.org/learn/advanced-learning-algorithms/home/week/4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset\n",
    "#### You can use Iris dataset for this task. It is a very popular dataset for machine learning and data science. It contains 150 samples of 3 different species of Iris flowers (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. \n",
    "Read more on this: https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "#### However, using more interesting and intricate datasets is much appreciated. You can use any dataset you want, but it should be a classification one. For example you can use breast cancer or wine datasets, which are also available in sklearn.datasets. Or you can use any other dataset you find interesting.\n",
    "P.S. In case you are not sure if your dataset is suitable, feel free to ask assistants :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "dir(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we have 150 entries (samples, infos about a flower). The columns being: Sepal Length, Sepal Width, Petal Length and Petal Width(features). Let's look at first two entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To undestand data little bit better, let's plot some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Sepal width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can clearly see, that even basing on those two parameters, we can clearly divide (classify) out data into several groups. For this, we will use decision tree classifier: https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "\n",
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "### Example of usage\n",
    "\n",
    "\n",
    "**Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression**. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / test split\n",
    "\n",
    "We train our model using training dataset and evaluate its performance basing on the test dataset. Reason to use two separate datasets is that our model learns its parameters from data, thus test set allows us to check its possibilities on completely new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size= 0.20)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning\n",
    "\n",
    "It learns its parameters (where it should split data and for what threshold value) basing on the training dataset. It is done by minimizing some cost function (e.g. Gini impurity or entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of produced tree\n",
    "\n",
    "You do not need to understand this piece of code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                     feature_names=iris.feature_names,\n",
    "                     class_names=iris.target_names,\n",
    "                     filled=True, rounded=True,\n",
    "                     special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction step\n",
    "\n",
    "Now we can use our model to predict which type has a flower, basing on its parameters.\n",
    "\n",
    "This is conducted basically via traversing the tree that you can see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also measure the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predictions == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get clearer intuition about predicion, let's look at those X, that should be labeled to some flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here you can traverse the tree above by yourself and make sure that prediction works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([X_test[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out implementation of Decision Tree Classifier\n",
    "\n",
    "Задача полягає в визначенні параметрів умов, які передбачатимуть до якої групи відносяться дані. Найпростіший прикладмашинного навчання.\n",
    "\n",
    "####  Gini impurity\n",
    "\n",
    "Decision trees use the concept of Gini impurity to describe how “pure” a node is. A node is pure (G = 0) if all its samples belong to the same class, while a node with many samples from many different classes will have a Gini closer to 1.\n",
    "\n",
    "$G = 1 - \\sum_{k=1}^{n}p_{k}^2$\n",
    "\n",
    "For example, if a node contains five samples, with two belonging to the first class (first flower), two of class 2, one of class 3 and none of class 4, then\n",
    "\n",
    "$G = 1 - (\\frac{2}{5})^2 - (\\frac{2}{5})^2 - (\\frac{1}{5})^2 = 0.64$\n",
    "\n",
    "#### Remarks \n",
    "- Нами також використано laplas smoothing, який прибирає значення gini=0, ставлячи у відповідність мале число. І це число стає меншим при більшій кількості sample. Тобто маючи більше даних, які підтверджують, що за визначеними умовами ця група даних відноситься до одного класу, -- ми ставимо число все ближче і ближче до 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    def __init__(self, X: npt.NDArray, y: npt.NDArray, laplas_smoothing: bool=True, alpha: float=0, d: int=0):\n",
    "        \"\"\"\n",
    "        :param X: numpy array of form [[feature1,feature2, ... featureN], ...] (i.e. [[1.5, 5.4, 3.2, 9.8] , ...] for case with iris d.s.)\n",
    "        :param y: numpy array of from [class1, class2, ...] (i.e. [0,1,1,2,1,0,...] for case with iris d.s.)\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.gini = self.calculate_gini_laplas(y, alpha, d) if laplas_smoothing else self.calculate_gini(y)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_gini(y: npt.NDArray) -> float:\n",
    "        _, counts = np.unique_counts(y)\n",
    "        total = np.sum(counts)\n",
    "        return 1 - np.sum((counts/total)**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_gini_laplas(y: npt.NDArray, alpha: float, d: int) -> float:\n",
    "        _, counts = np.unique_counts(y)\n",
    "        total = np.sum(counts)\n",
    "        return 1 - np.sum( ((counts+alpha)/(total+alpha*d)) ** 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth: int) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "        self.number_of_classes = None\n",
    "\n",
    "\n",
    "    def fit(self, X: npt.NDArray, y: npt.NDArray, alpha: float=1) -> None:\n",
    "        \"\"\"\n",
    "        Basically, function that performs all the training (building of a tree)\n",
    "        We recommend to use it as a wrapper of recursive building function\n",
    "        \"\"\"\n",
    "        self.number_of_classes = np.unique(y).size\n",
    "        self.tree = Node(X, y, True, alpha, self.number_of_classes)\n",
    "\n",
    "        features_count = X.shape[1]\n",
    "        uniques = [np.unique(X[:, f_i]) for f_i in range(features_count)]\n",
    "\n",
    "\n",
    "        def inner(root: Node, depth: int):\n",
    "            if depth >= self.max_depth:\n",
    "                return\n",
    "\n",
    "            max_info_gain = 0\n",
    "            for feature_index in range(features_count):\n",
    "                for threshold in uniques[feature_index]:\n",
    "                    left_data, right_data = self.split_data(root.X, root.y, feature_index, threshold)\n",
    "                    if left_data[0].size == 0 or right_data[0].size == 0:\n",
    "                        continue\n",
    "\n",
    "                    left = Node(left_data[0], left_data[1], True, alpha, self.number_of_classes)\n",
    "                    right = Node(right_data[0], right_data[1], True, alpha, self.number_of_classes)\n",
    "\n",
    "                    #maximize information gain\n",
    "                    left_info = left.gini * left.y.size / root.y.size\n",
    "                    right_info = right.gini * right.y.size / root.y.size\n",
    "                    cur_info_gain = root.gini - left_info - right_info\n",
    "                    if cur_info_gain > max_info_gain:\n",
    "                        max_info_gain = cur_info_gain\n",
    "                        root.feature_index = feature_index\n",
    "                        root.threshold = threshold\n",
    "                        root.left = left\n",
    "                        root.right = right\n",
    "\n",
    "            if root.left is None:\n",
    "                return\n",
    "            if root.left.gini != 0:\n",
    "                inner(root.left, depth+1)\n",
    "            if root.right.gini != 0:\n",
    "                inner(root.right, depth+1)\n",
    "\n",
    "        inner(self.tree, 0)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def split_data(X: npt.NDArray, y: npt.NDArray, feature_index: int, threshold) \\\n",
    "        -> tuple[tuple[npt.NDArray, npt.NDArray], tuple[npt.NDArray, npt.NDArray]]:\n",
    "        left, right = ([], []), ([], [])\n",
    "        for i in range(X.shape[0]):\n",
    "            if X[i, feature_index] <= threshold:\n",
    "                left[0].append(X[i])\n",
    "                left[1].append(y[i])\n",
    "            else:\n",
    "                right[0].append(X[i])\n",
    "                right[1].append(y[i])\n",
    "        return (np.array(left[0]), np.array(left[1])), (np.array(right[0]), np.array(right[1]))\n",
    "\n",
    "    def predict(self, X_test: npt.NDArray) -> list:\n",
    "        \"\"\"\n",
    "        Traverse the tree while there is a child\n",
    "        and return the predicted class for it\n",
    "        \"\"\"\n",
    "\n",
    "        def classify(node: Node, X: npt.ArrayLike) -> int:\n",
    "            if node.left is None:\n",
    "                ch, w = np.unique_counts(node.y)\n",
    "                return random.choices(ch, weights=w)[0]\n",
    "\n",
    "            if X[node.feature_index] <= node.threshold:\n",
    "                return classify(node.left, X)\n",
    "            return classify(node.right, X)\n",
    "\n",
    "        predictions = []\n",
    "        for X in X_test:\n",
    "            predictions.append(classify(self.tree, X))\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: MyDecisionTreeClassifier, X_test: list[list], y_test: list) -> float:\n",
    "    \"\"\"\n",
    "    Returns accuracy of the model (ratio of right guesses to the number of samples)\n",
    "    \"\"\"\n",
    "    my_predictions = model.predict(X_test)\n",
    "    return float(sum(my_predictions == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(5)\n",
    "my_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(my_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying our different laplas smoothing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.fit(X, y, 0.8)\n",
    "evaluate(my_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.fit(X, y, 0.2)\n",
    "evaluate(my_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.fit(X, y, 2)\n",
    "evaluate(my_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.fit(X, y, 5)\n",
    "evaluate(my_clf, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
